{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lien tuto: https://www.easy-tensorflow.com/tf-tutorials/autoencoders/noise-removal\n",
    "# libs\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "#pip install opencv-python\n",
    "import cv2\n",
    "\n",
    "# Import MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "print(\"Size of:\")\n",
    "print(\"- Training-set:\\t\\t{}\".format(len(mnist.train.labels)))\n",
    "print(\"- Test-set:\\t\\t{}\".format(len(mnist.test.labels)))\n",
    "print(\"- Validation-set:\\t{}\".format(len(mnist.validation.labels)))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "logs_path = \"logs/supprGrain\"  # path to the folder that we want to save the logs for Tensorboard\n",
    "learning_rate = 0.001  # The optimization learning rate\n",
    "epochs = 10  # Total number of training epochs\n",
    "batch_size = 100  # Training batch size\n",
    "display_freq = 100  # Frequency of displaying the training results\n",
    "\n",
    "# Network Parameters\n",
    "# We know that MNIST images are 28 pixels in each dimension.\n",
    "img_h = img_w = 28\n",
    "\n",
    "# Images are stored in one-dimensional arrays of this length.\n",
    "img_size_flat = img_h * img_w\n",
    "\n",
    "# number of units in the hidden layer\n",
    "h1 = 100\n",
    "\n",
    "# level of the noise in noisy data\n",
    "noise_level = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight and bais wrappers\n",
    "def weight_variable(name, shape):\n",
    "    \"\"\"\n",
    "    Create a weight variable with appropriate initialization\n",
    "    :param name: weight name\n",
    "    :param shape: weight shape\n",
    "    :return: initialized weight variable\n",
    "    \"\"\"\n",
    "    initer = tf.truncated_normal_initializer(stddev=0.01)\n",
    "    return tf.get_variable('W_' + name,\n",
    "                           dtype=tf.float32,\n",
    "                           shape=shape,\n",
    "                           initializer=initer)\n",
    "\n",
    "def bias_variable(name, shape):\n",
    "    \"\"\"\n",
    "    Create a bias variable with appropriate initialization\n",
    "    :param name: bias variable name\n",
    "    :param shape: bias variable shape\n",
    "    :return: initialized bias variable\n",
    "    \"\"\"\n",
    "    initial = tf.constant(0., shape=shape, dtype=tf.float32)\n",
    "    return tf.get_variable('b_' + name,\n",
    "                           dtype=tf.float32,\n",
    "                           initializer=initial)\n",
    "\n",
    "def fc_layer(x, num_units, name, use_relu=True):\n",
    "    \"\"\"\n",
    "    Create a fully-connected layer\n",
    "    :param x: input from previous layer\n",
    "    :param num_units: number of hidden units in the fully-connected layer\n",
    "    :param name: layer name\n",
    "    :param use_relu: boolean to add ReLU non-linearity (or not)\n",
    "    :return: The output array\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(name):\n",
    "        in_dim = x.get_shape()[1]\n",
    "        W = weight_variable(name, shape=[in_dim, num_units])\n",
    "        tf.summary.histogram('W', W)\n",
    "        b = bias_variable(name, [num_units])\n",
    "        tf.summary.histogram('b', b)\n",
    "        layer = tf.matmul(x, W)\n",
    "        layer += b\n",
    "        if use_relu:\n",
    "            layer = tf.nn.relu(layer)\n",
    "        return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "# Create graph\n",
    "# Placeholders for inputs (x), outputs(y)\n",
    "with tf.variable_scope('Input'):\n",
    "    x_original = tf.placeholder(tf.float32, shape=[None, img_size_flat], name='X_original')\n",
    "    x_noisy = tf.placeholder(tf.float32, shape=[None, img_size_flat], name='X_noisy')\n",
    "\n",
    "fc1 = fc_layer(x_noisy, h1, 'Hidden_layer', use_relu=True)\n",
    "out = fc_layer(fc1, img_size_flat, 'Output_layer', use_relu=False)\n",
    "\n",
    "# Define the loss function, optimizer, and accuracy\n",
    "with tf.variable_scope('Train'):\n",
    "    with tf.variable_scope('Loss'):\n",
    "        loss = tf.reduce_mean(tf.losses.mean_squared_error(x_original, out), name='loss')\n",
    "        tf.summary.scalar('loss', loss)\n",
    "    with tf.variable_scope('Optimizer'):\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, name='Adam-op').minimize(loss)\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Add 5 images from original, noisy and reconstructed samples to summaries\n",
    "tf.summary.image('original', tf.reshape(x_original, (-1, img_w, img_h, 1)), max_outputs=5)\n",
    "tf.summary.image('noisy', tf.reshape(x_noisy, (-1, img_w, img_h, 1)), max_outputs=5)\n",
    "tf.summary.image('reconstructed', tf.reshape(out, (-1, img_w, img_h, 1)), max_outputs=5)\n",
    "\n",
    "# Merge all the summaries\n",
    "merged = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch the graph (session)\n",
    "sess = tf.InteractiveSession() # using InteractiveSession instead of Session to test network in separate cell\n",
    "sess.run(init)\n",
    "train_writer = tf.summary.FileWriter(logs_path, sess.graph)\n",
    "num_tr_iter = int(mnist.train.num_examples / batch_size)\n",
    "global_step = 0\n",
    "for epoch in range(epochs):\n",
    "    print('Training epoch: {}'.format(epoch + 1))\n",
    "    for iteration in range(num_tr_iter):\n",
    "        batch_x, _ = mnist.train.next_batch(batch_size)\n",
    "        batch_x_noisy = batch_x + noise_level * np.random.normal(loc=0.0, scale=1.0, size=batch_x.shape)\n",
    "\n",
    "        global_step += 1\n",
    "        # Run optimization op (backprop)\n",
    "        feed_dict_batch = {x_original: batch_x, x_noisy: batch_x_noisy}\n",
    "        _, summary_tr = sess.run([optimizer, merged], feed_dict=feed_dict_batch)\n",
    "        train_writer.add_summary(summary_tr, global_step)\n",
    "\n",
    "        if iteration % display_freq == 0:\n",
    "            # Calculate and display the batch loss and accuracy\n",
    "            loss_batch = sess.run(loss,\n",
    "                                  feed_dict=feed_dict_batch)\n",
    "            print(\"iter {0:3d}:\\t Reconstruction loss={1:.3f}\".\n",
    "                  format(iteration, loss_batch))\n",
    "\n",
    "    # Run validation after every epoch\n",
    "    x_valid_original  = mnist.validation.images\n",
    "    x_valid_noisy = x_valid_original + noise_level * np.random.normal(loc=0.0, scale=1.0, size=x_valid_original.shape)\n",
    "\n",
    "    feed_dict_valid = {x_original: x_valid_original, x_noisy: x_valid_noisy}\n",
    "    loss_valid = sess.run(loss, feed_dict=feed_dict_valid)\n",
    "    print('---------------------------------------------------------')\n",
    "    print(\"Epoch: {0}, validation loss: {1:.3f}\".\n",
    "          format(epoch + 1, loss_valid))\n",
    "    print('---------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(original_images, noisy_images, reconstructed_images):\n",
    "    \"\"\"\n",
    "    Create figure of original and reconstructed image.\n",
    "    :param original_image: original images to be plotted, (?, img_h*img_w)\n",
    "    :param noisy_image: original images to be plotted, (?, img_h*img_w)\n",
    "    :param reconstructed_image: reconstructed images to be plotted, (?, img_h*img_w)\n",
    "    \"\"\"\n",
    "    num_images = original_images.shape[0]\n",
    "    fig, axes = plt.subplots(num_images, 3, figsize=(9, 9))\n",
    "    fig.subplots_adjust(hspace=.1, wspace=0)\n",
    "\n",
    "    img_h = img_w = np.sqrt(original_images.shape[-1]).astype(int)\n",
    "    for i, ax in enumerate(axes):\n",
    "        # Plot image.\n",
    "        ax[0].imshow(original_images[i].reshape((img_h, img_w)), cmap='gray')\n",
    "        ax[1].imshow(noisy_images[i].reshape((img_h, img_w)), cmap='gray')\n",
    "        ax[2].imshow(reconstructed_images[i].reshape((img_h, img_w)), cmap='gray')\n",
    "\n",
    "        # Remove ticks from the plot.\n",
    "        for sub_ax in ax:\n",
    "            sub_ax.set_xticks([])\n",
    "            sub_ax.set_yticks([])\n",
    "\n",
    "    for ax, col in zip(axes[0], [\"Original Image\", \"Noisy Image\", \"Reconstructed Image\"]):\n",
    "        ax.set_title(col)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the network after training\n",
    "# Make a noisy image\n",
    "test_samples = 5\n",
    "x_test = mnist.test.images[:test_samples]\n",
    "x_test_noisy = x_test + noise_level * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape)\n",
    "# Reconstruct a clean image from noisy image\n",
    "x_reconstruct = sess.run(out, feed_dict={x_noisy: x_test_noisy})\n",
    "# Calculate the loss between reconstructed image and original image\n",
    "loss_test = sess.run(loss, feed_dict={x_original: x_test, x_noisy: x_test_noisy})\n",
    "print('---------------------------------------------------------')\n",
    "print(\"Test loss of original image compared to reconstructed image : {0:.3f}\".format(loss_test))\n",
    "print('---------------------------------------------------------')\n",
    "\n",
    "# Plot original image, noisy image and reconstructed image\n",
    "plot_images(x_test, x_test_noisy, x_reconstruct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close the session after you are done with testing\n",
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
